---
title: "Lifted Neural Networks"
date: 2018-06-01
publishDate: 2020-04-14T03:12:12.973598Z
authors: ["Armin Askari", "Geoffrey Negiar", "Rajiv Sambharya", "Laurent El Ghaoui"]
publication_types: ["3"]
abstract: "We describe a novel family of models of multi-layer feedforward neural networks in which the activation functions are encoded via penalties in the training problem. Our approach is based on representing a non-decreasing activation function as the argmin of an appropriate convex optimization problem. The new framework allows for algorithms such as block-coordinate descent methods to be applied, in which each step is composed of a simple (no hidden layer) supervised learning problem that is parallelizable across data points and/or layers. Experiments indicate that the pro- posed models provide excellent initial guesses for weights for standard neural networks. In addition, the model provides avenues for interesting extensions, such as robustness against noisy inputs and optimizing over parameters in activation functions."
featured: false
publication: "*arXiv:1805.01532 [cs, stat]*"
tags: ["Computer Science - Machine Learning", "Statistics - Machine Learning"]
url_pdf: "http://arxiv.org/abs/1805.01532"
---

