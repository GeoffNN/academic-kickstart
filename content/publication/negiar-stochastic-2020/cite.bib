@article{negiar_stochastic_2020,
 abstract = {We propose a novel Stochastic Frank-Wolfe (a.k.a. Conditional Gradient) algorithm with a fixed batch size tailored to the constrained optimization of a finite sum of smooth objectives. The design of our method hinges on a primal-dual interpretation of the Frank-Wolfe algorithm. Recent work to design stochastic variants of the Frank-Wolfe algorithm falls into two categories: algorithms with increasing batch size, and algorithms with a given, constant, batch size. The former have faster convergence rates but are impractical; the latter are practical but slower. The proposed method combines the advantages of both: it converges for unit batch size, and has faster theoretical worst-case rates than previous unit batch size algorithms. Our experiments also show faster empirical convergence than previous unit batch size methods for several tasks. Finally, we construct a stochastic estimator of the Frank-Wolfe gap. It allows us to bound the true Frank-Wolfe gap, which in the convex setting bounds the primal-dual gap in the convex case while in general is a measure of stationarity. Our gap estimator can therefore be used as a practical stopping criterion in all cases.},
 author = {Négiar, Geoffrey and Dresdner, Gideon and Tsai, Alicia and Ghaoui, Laurent El and Locatello, Francesco and Pedregosa, Fabian},
 copyright = {All rights reserved},
 file = {arXiv Fulltext PDF:/home/geoff/Zotero/storage/IXVSSRIV/Négiar et al. - 2020 - Stochastic Frank-Wolfe for Constrained Finite-Sum .pdf:application/pdf;arXiv.org Snapshot:/home/geoff/Zotero/storage/DWYSC5JD/2002.html:text/html},
 journal = {arXiv:2002.11860 [cs, math]},
 keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
 month = {February},
 note = {arXiv: 2002.11860},
 title = {Stochastic Frank-Wolfe for Constrained Finite-Sum Minimization},
 url = {http://arxiv.org/abs/2002.11860},
 urldate = {2020-04-14},
 year = {2020}
}

